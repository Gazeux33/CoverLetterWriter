{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Follow Prompt Template Tuto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load local model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "BASE_URL = \"http://localhost:1234/v1\"\n",
    "MODEL_NAME = \"deepseek-r1-distill-llama-8b\"\n",
    "\n",
    "\n",
    "model = ChatOpenAI(base_url=BASE_URL,api_key=\"xxx\",name=MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a ChatPromptTemplate using a template string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[HumanMessage(content='Tell me a joke about cats', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "template = \"Tell me a joke about {topic}\"\n",
    "prompt_template = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "prompt = prompt_template.invoke({\"topic\":\"cats\"})\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt with multiple placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[HumanMessage(content='Tell me a funny story about a panda', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "template_multiple = \"Tell me a {adjective} story about a {animal}\"\n",
    "prompt_template = ChatPromptTemplate.from_template(template_multiple)\n",
    "prompt = prompt_template.invoke({\"adjective\":\"funny\", \"animal\":\"panda\"})\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt with Human and System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[SystemMessage(content='You are a comedian who tell jokes about lawyers', additional_kwargs={}, response_metadata={}), HumanMessage(content=' tell me 3 jokes', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    (\"system\" , \"You are a comedian who tell jokes about {topic}\"),\n",
    "    (\"human\",\" tell me {joke_count} jokes\") \n",
    "]\n",
    "prompt_template = ChatPromptTemplate.from_messages(messages)\n",
    "prompt = prompt_template.invoke({\"topic\" : \"lawyers\", \"joke_count\":3})\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use prompt with model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, so I'm trying to come up with some jokes about lawyers. Hmm, where do I start? Well, lawyers are often stereotyped in humor because of their reputation for being formal, maybe a bit stuffy, or overly concerned with details. So, maybe I can play on those stereotypes.\n",
      "\n",
      "First, thinking about the law itself, there's a lot of jargon and terms that might be funny when twisted into something unexpected. Like, \"access to justice\" could be humorously rephrased as \"denying access until the justice is paid.\" That plays on the idea that legal services can be expensive, so people might have limited access.\n",
      "\n",
      "Next, I remember hearing a joke about a lawyer who was arrested for drunk driving. His defense was that he was \"under the influence\" of his clients' files. That's clever because it uses a common situation (drunk driving) and ties it to a profession that deals with documents and evidence. So, the humor comes from the unexpected connection.\n",
      "\n",
      "Lastly, maybe something about court procedures. A lawyer could joke about how they always have to \"charge by the hour,\" but if you're in trouble, you might prefer paying per hour than being in court for too long. It's a play on the billing practice and the experience of being in legal trouble.\n",
      "\n",
      "I think these jokes use wordplay and common perceptions to create humor without crossing into offensive territory. They rely on the audience's familiarity with lawyer stereotypes, which helps make the jokes relatable.\n",
      "</think>\n",
      "\n",
      "Here are three humorous takes on lawyer-related jokes, each leveraging common stereotypes and wordplay:\n",
      "\n",
      "1. **Access to Justice**: A lawyer once quipped, \"I'm all for 'access to justice,' but I draw the line when it comes to denying access until the justice is paid!\"\n",
      "\n",
      "2. **Drunk Driving Defense**: There was a lawyer who got busted for drunk driving. His defense? \"I was under the influence of my clients' files!\"\n",
      "\n",
      "3. **Billing Practices**: A lawyer jokingly mentioned, \"You know you're in trouble when paying by the hour feels like a bargain compared to the time spent in court.\"\n",
      "\n",
      "These jokes play on the stereotypes of lawyers being formal and detail-oriented, using humor rooted in familiar situations and professional jargon.\n"
     ]
    }
   ],
   "source": [
    "result = model.invoke(prompt)\n",
    "print(result.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
